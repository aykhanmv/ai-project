{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as model\n",
    "\n",
    "\n",
    "class VGG16(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes, pretrained=False):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.vgg16 = model.vgg16(pretrained=pretrained)\n",
    "        self.vgg16.classifier[-1] = torch.nn.Linear(in_features=4096, out_features=num_classes, bias=True)\n",
    "\n",
    "    def forward(self, image):\n",
    "        out = self.vgg16(image)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import softmax\n",
    "from torch.nn.functional import cross_entropy\n",
    "from torchmetrics import F1Score\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.models import vgg16\n",
    "from datasets.dataset_retrieval import custom_dataset\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import tqdm\n",
    "from torchvision.datasets import ImageFolder\n",
    "import os\n",
    "\n",
    "save_model_path = \"checkpoints/\"\n",
    "\n",
    "\n",
    "def val(model, data_val, loss_function, writer, epoch, device):\n",
    "    f1score = 0\n",
    "    f1 = F1Score(num_classes=47, task='multiclass')\n",
    "    data_iterator = enumerate(data_val)  # Take batches\n",
    "    f1_list = []\n",
    "    f1t_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()  # Switch model to evaluation mode\n",
    "        tq = tqdm.tqdm(total=len(data_val))\n",
    "        tq.set_description('Validation:')\n",
    "\n",
    "        total_loss = 0\n",
    "\n",
    "        for _, batch in data_iterator:\n",
    "            # Forward propagation\n",
    "            image, label = batch\n",
    "            image = image.to(device)\n",
    "            label = label.to(device).long()  # Convert labels to LongTensor\n",
    "            \n",
    "            pred = model(image)\n",
    "\n",
    "            loss = loss_function(pred, label)\n",
    "\n",
    "            pred = pred.softmax(dim=1)\n",
    "            \n",
    "            f1_list.extend(torch.argmax(pred, dim=1).tolist())\n",
    "            f1t_list.extend(label.tolist())  # Labels are already in LongTensor format\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            tq.update(1)\n",
    "\n",
    "    f1score = f1(torch.tensor(f1_list), torch.tensor(f1t_list))\n",
    "    writer.add_scalar(\"Validation F1\", f1score, epoch)\n",
    "    writer.add_scalar(\"Validation Loss\", total_loss / len(data_val), epoch)\n",
    "\n",
    "    tq.close()\n",
    "    print(\"F1 score: \", f1score)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, loss_fn, n_epochs, device, log_dir):\n",
    "    # Scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\n",
    "    writer = SummaryWriter(log_dir=os.path.join('runs', log_dir))\n",
    "\n",
    "    model.to(device)  # Move the model to the specified device (e.g., GPU or CPU)\n",
    "    model.train()  # Set the model to training mode\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        tq = tqdm.tqdm(total=len(train_loader))\n",
    "        tq.set_description('epoch %d' % epoch)\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)  # Move the batch of images to the specified device\n",
    "            labels = labels.to(device).long()  # Convert labels to LongTensor\n",
    "            \n",
    "            optimizer.zero_grad()  # Reset the gradients of the optimizer\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            outputs = outputs.softmax(dim=1)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update model parameters\n",
    "            optimizer.step()\n",
    "            # Scheduler.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            tq.set_postfix(loss_st='%.6f' % loss.item())\n",
    "            tq.update(1)\n",
    "\n",
    "        writer.add_scalar(\"Training Loss\", running_loss / len(train_loader), epoch)\n",
    "\n",
    "        tq.close()\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, n_epochs, epoch_loss))\n",
    "\n",
    "        # Check the performance of the model on the validation dataset\n",
    "        val(model, val_loader, loss_fn, writer, epoch, device)\n",
    "\n",
    "        # Save the model in .pth format\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }\n",
    "\n",
    "        torch.save(checkpoint, os.path.join(save_model_path, log_dir + '.pth'))\n",
    "        print(\"Saved the model to \" + save_model_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def main(model_name, optimizer_name, lr, pretrained, log_dir):\n",
    "    \n",
    "#     device = \"cuda\"\n",
    "#     torch.cuda.set_per_process_memory_fraction(0.8, device=0)  # Limit GPU memory to 80%\n",
    "\n",
    "    \n",
    "#     tr_train = transforms.Compose([\n",
    "#         transforms.RandomHorizontalFlip(0.5),\n",
    "#         transforms.RandomRotation(30),\n",
    "#         # transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "#         transforms.Resize([250, 250]),\n",
    "#         transforms.RandomCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "\n",
    "#     ])\n",
    "    \n",
    "#     tr_val = transforms.Compose([\n",
    "#         transforms.Resize([224, 224]),\n",
    "#         transforms.ToTensor(),\n",
    "\n",
    "#     ])\n",
    "\n",
    "#     train_data = ImageFolder(root=r\"datasets\\split_data\\train\", transform=tr_train)\n",
    "#     val_data = ImageFolder(root=r\"datasets\\split_data\\val\", transform=tr_val)\n",
    "\n",
    "#     train_loader = DataLoader(\n",
    "#         train_data,\n",
    "#         batch_size=8,\n",
    "#         shuffle=True,\n",
    "\n",
    "#     )\n",
    "\n",
    "#     val_loader = DataLoader(\n",
    "#         val_data,\n",
    "#         batch_size=8,\n",
    "#         drop_last=True,\n",
    "\n",
    "#     )\n",
    "    \n",
    "#     max_epoch = 20\n",
    "\n",
    "#     if model_name=='resnet':\n",
    "#         model = resnet18(num_classes=4, pretrained=pretrained).to(device)\n",
    "#     elif model_name=='vgg':\n",
    "#         model = VGG16(num_classes=4, pretrained=pretrained).to(device)\n",
    "    \n",
    "#     if optimizer_name=='sgd':\n",
    "#         optimizer = SGD(model.parameters(), lr=lr, momentum = 0.9)\n",
    "#     elif optimizer_name=='adam':\n",
    "#         optimizer = Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "#     loss = nn.CrossEntropyLoss()\n",
    "\n",
    "#     train(model, train_loader, val_loader, optimizer, loss, max_epoch, device, log_dir)\n",
    "    \n",
    "    \n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "    \n",
    "#     # main(model_name='vgg', optimizer_name='sgd', lr=1e-3, pretrained=False, log_dir='vgg_sgd')\n",
    "#     # main(model_name='vgg', optimizer_name='adam', lr=1e-4, pretrained=False, log_dir='vgg_adam')\n",
    "    \n",
    "#     main(model_name='vgg', optimizer_name='sgd', lr=1e-3, pretrained=True, log_dir='vgg_sgd_pretrained')\n",
    "#     main(model_name='vgg', optimizer_name='adam', lr=1e-4, pretrained=True, log_dir='vgg_adam_pretrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "def test(model, test_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)  # Get the predicted class\n",
    "            total += labels.size(0)  # Total number of labels\n",
    "            correct += (predicted == labels).sum().item()  # Correct predictions\n",
    "\n",
    "    accuracy = 100 * correct / total  # Accuracy in percentage\n",
    "    print(f'Accuracy on the test set: {accuracy:.2f}%')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19348\\408221922.py:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from checkpoints\\vgg_sgd_pretrained.pth\n",
      "Test dataset size: 804 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 101/101 [00:04<00:00, 21.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 84.20%\n",
      "Test Accuracy for vgg (vgg_sgd_pretrained): 0.8420\n",
      "Model loaded successfully from checkpoints\\vgg_adam_pretrained.pth\n",
      "Test dataset size: 804 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 101/101 [00:04<00:00, 20.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 79.73%\n",
      "Test Accuracy for vgg (vgg_adam_pretrained): 0.7973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as model\n",
    "from torchmetrics import F1Score\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "# Define the VGG16 model class\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.vgg16 = model.vgg16(pretrained=pretrained)\n",
    "        self.vgg16.classifier[-1] = torch.nn.Linear(in_features=4096, out_features=num_classes, bias=True)\n",
    "\n",
    "    def forward(self, image):\n",
    "        out = self.vgg16(image)\n",
    "        return out\n",
    "\n",
    "# Function to evaluate accuracy on the test dataset\n",
    "def test(model, test_loader, device):\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    model.eval()  # Switch model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)  # Get the predicted class\n",
    "\n",
    "            # Update counts\n",
    "            correct_preds += (predicted == labels).sum().item()\n",
    "            total_preds += labels.size(0)\n",
    "\n",
    "    accuracy = correct_preds / total_preds\n",
    "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# Function to load model from checkpoint\n",
    "def load_model(checkpoint_path, model, device):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"Model loaded successfully from {checkpoint_path}\")\n",
    "    return model\n",
    "\n",
    "# Function to prepare the test dataset\n",
    "def prepare_test_data(test_data_path, batch_size):\n",
    "    tr_test = transforms.Compose([\n",
    "        transforms.Resize([224, 224]),  # Resize images\n",
    "        transforms.ToTensor(),  # Convert to tensor\n",
    "    ])\n",
    "    \n",
    "    # Load the test dataset\n",
    "    test_data = ImageFolder(root=test_data_path, transform=tr_test)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)  # No need to shuffle for testing\n",
    "    print(f\"Test dataset size: {len(test_data)} samples\")\n",
    "    return test_loader\n",
    "\n",
    "def main(model_name, optimizer_name, lr, pretrained, log_dir, test_data_path):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    torch.cuda.set_per_process_memory_fraction(0.8, device=0)  # Limit GPU memory to 80%\n",
    "\n",
    "    if model_name == 'vgg':\n",
    "        model = VGG16(num_classes=4, pretrained=pretrained).to(device)\n",
    "\n",
    "    # Load the model\n",
    "    checkpoint_path = os.path.join(\"checkpoints\", log_dir + '.pth')\n",
    "    model = load_model(checkpoint_path, model, device)\n",
    "\n",
    "    # Prepare the test data\n",
    "    test_loader = prepare_test_data(test_data_path, batch_size=8)\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    test_accuracy = test(model, test_loader, device)\n",
    "    print(f\"Test Accuracy for {model_name} ({log_dir}): {test_accuracy:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_data_path = r\"datasets\\split_data\\test\"  # Path to your test dataset\n",
    "\n",
    "    # Example: Test with a pretrained VGG model trained with SGD\n",
    "    main(model_name='vgg', optimizer_name='sgd', lr=1e-3, pretrained=True, log_dir='vgg_sgd_pretrained', test_data_path=test_data_path)\n",
    "    main(model_name='vgg', optimizer_name='sgd', lr=1e-3, pretrained=True, log_dir='vgg_adam_pretrained', test_data_path=test_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "epoch 0: 100%|██████████| 350/350 [00:55<00:00,  6.36it/s, loss_st=1.386817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.3874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:04<00:00, 12.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.2875)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 350/350 [00:40<00:00,  8.67it/s, loss_st=1.387679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 1.3867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.2900)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2: 100%|██████████| 350/350 [00:40<00:00,  8.63it/s, loss_st=1.380155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 1.3865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.3100)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3: 100%|██████████| 350/350 [00:40<00:00,  8.67it/s, loss_st=1.396382]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 1.3861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.3050)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4: 100%|██████████| 350/350 [00:40<00:00,  8.65it/s, loss_st=1.390230]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 1.3865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.3075)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5: 100%|██████████| 350/350 [00:40<00:00,  8.69it/s, loss_st=1.367505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 1.3857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.2825)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6: 100%|██████████| 350/350 [00:40<00:00,  8.68it/s, loss_st=1.377220]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 1.3854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.3050)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7: 100%|██████████| 350/350 [00:40<00:00,  8.68it/s, loss_st=1.373549]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 1.3851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.2800)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8: 100%|██████████| 350/350 [00:40<00:00,  8.64it/s, loss_st=1.403634]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 1.3839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.3000)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9: 100%|██████████| 350/350 [00:53<00:00,  6.59it/s, loss_st=1.398409]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 1.3840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:04<00:00, 10.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.2800)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 10: 100%|██████████| 350/350 [00:45<00:00,  7.61it/s, loss_st=1.378305]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 1.3826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 23.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.2750)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 11: 100%|██████████| 350/350 [00:40<00:00,  8.65it/s, loss_st=1.373021]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 1.3826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 23.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.3025)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 12: 100%|██████████| 350/350 [00:40<00:00,  8.68it/s, loss_st=1.364956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 1.3826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.2575)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 13: 100%|██████████| 350/350 [00:40<00:00,  8.65it/s, loss_st=1.365648]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 1.3807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.2975)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 14: 100%|██████████| 350/350 [00:40<00:00,  8.66it/s, loss_st=1.365146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 1.3794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.3500)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 15: 100%|██████████| 350/350 [00:40<00:00,  8.65it/s, loss_st=1.377323]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 1.3789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.3675)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 16: 100%|██████████| 350/350 [00:40<00:00,  8.66it/s, loss_st=1.281729]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 1.3709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.3800)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 17: 100%|██████████| 350/350 [00:40<00:00,  8.68it/s, loss_st=1.324657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: 1.3718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.3700)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 18: 100%|██████████| 350/350 [00:40<00:00,  8.68it/s, loss_st=1.476541]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 1.3561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.3900)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 19: 100%|██████████| 350/350 [00:51<00:00,  6.75it/s, loss_st=1.233415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 1.3483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.3175)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0: 100%|██████████| 350/350 [00:48<00:00,  7.19it/s, loss_st=1.386729]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.3881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.2475)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 350/350 [00:48<00:00,  7.21it/s, loss_st=1.393885]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 1.3897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.2500)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2: 100%|██████████| 350/350 [00:48<00:00,  7.24it/s, loss_st=1.383340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 1.3865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.2500)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3: 100%|██████████| 350/350 [00:48<00:00,  7.21it/s, loss_st=1.384620]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 1.3865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.2500)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4: 100%|██████████| 350/350 [00:48<00:00,  7.21it/s, loss_st=1.387558]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 1.3864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 23.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.2500)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5: 100%|██████████| 350/350 [00:48<00:00,  7.22it/s, loss_st=1.420360]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 1.3867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 23.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.2500)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6: 100%|██████████| 350/350 [00:48<00:00,  7.23it/s, loss_st=1.389916]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 1.3866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.2500)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7: 100%|██████████| 350/350 [00:48<00:00,  7.17it/s, loss_st=1.384415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 1.3866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 21.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.2500)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8: 100%|██████████| 350/350 [01:04<00:00,  5.43it/s, loss_st=1.386416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 1.3865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.2500)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9: 100%|██████████| 350/350 [00:48<00:00,  7.20it/s, loss_st=1.382223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 1.3866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.2500)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 10: 100%|██████████| 350/350 [00:48<00:00,  7.22it/s, loss_st=1.387883]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 1.3867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.2500)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 11: 100%|██████████| 350/350 [00:48<00:00,  7.24it/s, loss_st=1.386646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 1.3866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.2500)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 12: 100%|██████████| 350/350 [00:48<00:00,  7.22it/s, loss_st=1.385634]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 1.3865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.2500)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 13: 100%|██████████| 350/350 [00:48<00:00,  7.23it/s, loss_st=1.384686]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 1.3865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 23.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.2500)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 14: 100%|██████████| 350/350 [18:07<00:00,  3.11s/it, loss_st=1.385587]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 1.3865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 21.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.2500)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 15: 100%|██████████| 350/350 [00:58<00:00,  6.02it/s, loss_st=1.386529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 1.3864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 20.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.2500)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 16: 100%|██████████| 350/350 [00:58<00:00,  5.98it/s, loss_st=1.385935]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 1.3866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 20.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.2500)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 17:  22%|██▏       | 78/350 [00:13<00:45,  5.98it/s, loss_st=1.385767]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 61\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     60\u001b[0m     main(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvgg\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msgd\u001b[39m\u001b[38;5;124m'\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0005\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, log_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvgg_sgd\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 61\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvgg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.00005\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvgg_adam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 54\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(model_name, optimizer_name, lr, pretrained, log_dir)\u001b[0m\n\u001b[0;32m     50\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m Adam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[0;32m     52\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m---> 54\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 97\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, val_loader, optimizer, loss_fn, n_epochs, device, log_dir)\u001b[0m\n\u001b[0;32m     94\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# Scheduler.step()\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m tq\u001b[38;5;241m.\u001b[39mset_postfix(loss_st\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%.6f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     99\u001b[0m tq\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main(model_name, optimizer_name, lr, pretrained, log_dir):\n",
    "    \n",
    "    device = \"cuda\"\n",
    "    torch.cuda.set_per_process_memory_fraction(0.8, device=0)  # Limit GPU memory to 80%\n",
    "\n",
    "    \n",
    "    tr_train = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.RandomRotation(30),\n",
    "        # transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "        transforms.Resize([250, 250]),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "\n",
    "    ])\n",
    "    \n",
    "    tr_val = transforms.Compose([\n",
    "        transforms.Resize([224, 224]),\n",
    "        transforms.ToTensor(),\n",
    "\n",
    "    ])\n",
    "\n",
    "    train_data = ImageFolder(root=r\"datasets\\split_data\\train\", transform=tr_train)\n",
    "    val_data = ImageFolder(root=r\"datasets\\split_data\\val\", transform=tr_val)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_data,\n",
    "        batch_size=8,\n",
    "        shuffle=True,\n",
    "\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_data,\n",
    "        batch_size=8,\n",
    "        drop_last=True,\n",
    "\n",
    "    )\n",
    "    \n",
    "    max_epoch = 20\n",
    "\n",
    "    if model_name=='resnet':\n",
    "        model = resnet18(num_classes=4, pretrained=pretrained).to(device)\n",
    "    elif model_name=='vgg':\n",
    "        model = VGG16(num_classes=4, pretrained=pretrained).to(device)\n",
    "    \n",
    "    if optimizer_name=='sgd':\n",
    "        optimizer = SGD(model.parameters(), lr=lr, momentum = 0.9)\n",
    "    elif optimizer_name=='adam':\n",
    "        optimizer = Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    train(model, train_loader, val_loader, optimizer, loss, max_epoch, device, log_dir)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    \n",
    "    main(model_name='vgg', optimizer_name='sgd', lr=0.0005, pretrained=False, log_dir='vgg_sgd')\n",
    "    main(model_name='vgg', optimizer_name='adam', lr=0.00005, pretrained=False, log_dir='vgg_adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_18680\\3006699582.py:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from checkpoints\\vgg_sgd.pth\n",
      "Test dataset size: 804 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 101/101 [00:08<00:00, 11.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 29.35%\n",
      "Test Accuracy for vgg (vgg_sgd): 0.2935\n",
      "Model loaded successfully from checkpoints\\vgg_adam.pth\n",
      "Test dataset size: 804 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 101/101 [00:04<00:00, 21.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 25.00%\n",
      "Test Accuracy for vgg (vgg_adam): 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as model\n",
    "from torchmetrics import F1Score\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "# Define the VGG16 model class\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.vgg16 = model.vgg16(pretrained=pretrained)\n",
    "        self.vgg16.classifier[-1] = torch.nn.Linear(in_features=4096, out_features=num_classes, bias=True)\n",
    "\n",
    "    def forward(self, image):\n",
    "        out = self.vgg16(image)\n",
    "        return out\n",
    "\n",
    "# Function to evaluate accuracy on the test dataset\n",
    "def test(model, test_loader, device):\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    model.eval()  # Switch model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)  # Get the predicted class\n",
    "\n",
    "            # Update counts\n",
    "            correct_preds += (predicted == labels).sum().item()\n",
    "            total_preds += labels.size(0)\n",
    "\n",
    "    accuracy = correct_preds / total_preds\n",
    "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# Function to load model from checkpoint\n",
    "def load_model(checkpoint_path, model, device):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"Model loaded successfully from {checkpoint_path}\")\n",
    "    return model\n",
    "\n",
    "# Function to prepare the test dataset\n",
    "def prepare_test_data(test_data_path, batch_size):\n",
    "    tr_test = transforms.Compose([\n",
    "        transforms.Resize([224, 224]),  # Resize images\n",
    "        transforms.ToTensor(),  # Convert to tensor\n",
    "    ])\n",
    "    \n",
    "    # Load the test dataset\n",
    "    test_data = ImageFolder(root=test_data_path, transform=tr_test)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)  # No need to shuffle for testing\n",
    "    print(f\"Test dataset size: {len(test_data)} samples\")\n",
    "    return test_loader\n",
    "\n",
    "def main(model_name, optimizer_name, lr, pretrained, log_dir, test_data_path):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    torch.cuda.set_per_process_memory_fraction(0.8, device=0)  # Limit GPU memory to 80%\n",
    "\n",
    "    if model_name == 'vgg':\n",
    "        model = VGG16(num_classes=4, pretrained=pretrained).to(device)\n",
    "\n",
    "    # Load the model\n",
    "    checkpoint_path = os.path.join(\"checkpoints\", log_dir + '.pth')\n",
    "    model = load_model(checkpoint_path, model, device)\n",
    "\n",
    "    # Prepare the test data\n",
    "    test_loader = prepare_test_data(test_data_path, batch_size=8)\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    test_accuracy = test(model, test_loader, device)\n",
    "    print(f\"Test Accuracy for {model_name} ({log_dir}): {test_accuracy:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_data_path = r\"datasets\\split_data\\test\"  # Path to your test dataset\n",
    "\n",
    "    # Example: Test with a pretrained VGG model trained with SGD\n",
    "    main(model_name='vgg', optimizer_name='sgd', lr=1e-3, pretrained=True, log_dir='vgg_sgd', test_data_path=test_data_path)\n",
    "    main(model_name='vgg', optimizer_name='sgd', lr=1e-3, pretrained=True, log_dir='vgg_adam', test_data_path=test_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label Distribution in Training Set:\n",
      "Class 3: 699 samples\n",
      "Class 1: 699 samples\n",
      "Class 2: 699 samples\n",
      "Class 0: 699 samples\n",
      "\n",
      "Label Distribution in Validation (Test) Set:\n",
      "Class 0: 100 samples\n",
      "Class 1: 100 samples\n",
      "Class 2: 100 samples\n",
      "Class 3: 100 samples\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def main():\n",
    "    device = \"cuda\"\n",
    "    torch.cuda.set_per_process_memory_fraction(0.8, device=0)  # Limit GPU memory to 80%\n",
    "\n",
    "    # Data transformations\n",
    "    tr_train = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.Resize([250, 250]),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    tr_val = transforms.Compose([\n",
    "        transforms.Resize([224, 224]),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Load train and validation datasets\n",
    "    train_data = ImageFolder(root=r\"datasets\\split_data\\train\", transform=tr_train)\n",
    "    val_data = ImageFolder(root=r\"datasets\\split_data\\val\", transform=tr_val)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=8, drop_last=True)\n",
    "\n",
    "    # Analyze label distribution for training data\n",
    "    train_labels = []\n",
    "    for inputs, labels in train_loader:\n",
    "        train_labels.extend(labels.tolist())\n",
    "    train_label_counts = Counter(train_labels)\n",
    "\n",
    "    print(\"\\nLabel Distribution in Training Set:\")\n",
    "    for label, count in train_label_counts.items():\n",
    "        print(f\"Class {label}: {count} samples\")\n",
    "\n",
    "    # Analyze label distribution for validation data\n",
    "    val_labels = []\n",
    "    for inputs, labels in val_loader:\n",
    "        val_labels.extend(labels.tolist())\n",
    "    val_label_counts = Counter(val_labels)\n",
    "\n",
    "    print(\"\\nLabel Distribution in Validation (Test) Set:\")\n",
    "    for label, count in val_label_counts.items():\n",
    "        print(f\"Class {label}: {count} samples\")\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
