{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as model\n",
    "\n",
    "\n",
    "class VGG16(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes, pretrained=False):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.vgg16 = model.vgg16(pretrained=pretrained)\n",
    "        self.vgg16.classifier[-1] = torch.nn.Linear(in_features=4096, out_features=num_classes, bias=True)\n",
    "\n",
    "    def forward(self, image):\n",
    "        out = self.vgg16(image)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import softmax\n",
    "from torchmetrics import F1Score\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18, vgg16\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "save_model_path = \"checkpoints/\"\n",
    "\n",
    "\n",
    "def val(model, data_val, loss_function, writer, epoch, device):\n",
    "    f1score = 0\n",
    "    f1 = F1Score(num_classes=47, task='multiclass')\n",
    "    data_iterator = enumerate(data_val)  # Take batches\n",
    "    f1_list = []\n",
    "    f1t_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()  # Switch model to evaluation mode\n",
    "        tq = tqdm.tqdm(total=len(data_val))\n",
    "        tq.set_description('Validation:')\n",
    "\n",
    "        total_loss = 0\n",
    "\n",
    "        for _, batch in data_iterator:\n",
    "            # Forward propagation\n",
    "            image, label = batch\n",
    "            image = image.to(device)\n",
    "            label = label.to(device).long()  # Convert labels to LongTensor\n",
    "            \n",
    "            pred = model(image)\n",
    "\n",
    "            loss = loss_function(pred, label)\n",
    "\n",
    "            pred = pred.softmax(dim=1)\n",
    "            \n",
    "            f1_list.extend(torch.argmax(pred, dim=1).tolist())\n",
    "            f1t_list.extend(label.tolist())  # Labels are already in LongTensor format\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            tq.update(1)\n",
    "\n",
    "    f1score = f1(torch.tensor(f1_list), torch.tensor(f1t_list))\n",
    "    writer.add_scalar(\"Validation F1\", f1score, epoch)\n",
    "    writer.add_scalar(\"Validation Loss\", total_loss / len(data_val), epoch)\n",
    "\n",
    "    tq.close()\n",
    "    print(\"F1 score: \", f1score)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, loss_fn, n_epochs, device, log_dir):\n",
    "    writer = SummaryWriter(log_dir=os.path.join('runs', log_dir))\n",
    "\n",
    "    model.to(device)  # Move the model to the specified device (e.g., GPU or CPU)\n",
    "    model.train()  # Set the model to training mode\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        tq = tqdm.tqdm(total=len(train_loader))\n",
    "        tq.set_description('epoch %d' % epoch)\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)  # Move the batch of images to the specified device\n",
    "            labels = labels.to(device).long()  # Convert labels to LongTensor\n",
    "            \n",
    "            optimizer.zero_grad()  # Reset the gradients of the optimizer\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            outputs = outputs.softmax(dim=1)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update model parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            tq.set_postfix(loss_st='%.6f' % loss.item())\n",
    "            tq.update(1)\n",
    "\n",
    "        writer.add_scalar(\"Training Loss\", running_loss / len(train_loader), epoch)\n",
    "\n",
    "        tq.close()\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, n_epochs, epoch_loss))\n",
    "\n",
    "        # Check the performance of the model on the validation dataset\n",
    "        val(model, val_loader, loss_fn, writer, epoch, device)\n",
    "\n",
    "        # Save the model in .pth format\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }\n",
    "\n",
    "        torch.save(checkpoint, os.path.join(save_model_path, log_dir + '.pth'))\n",
    "        print(\"Saved the model to \" + save_model_path)\n",
    "\n",
    "\n",
    "def main(model_name, optimizer_name, lr, pretrained, log_dir):\n",
    "    device = \"cuda\"\n",
    "    torch.cuda.set_per_process_memory_fraction(0.8, device=0)  # Limit GPU memory to 80%\n",
    "\n",
    "    # Data transformations\n",
    "    tr_train = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.Resize([250, 250]),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    tr_val = transforms.Compose([\n",
    "        transforms.Resize([224, 224]),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Dataset and DataLoader\n",
    "    train_data = ImageFolder(root=r\"datasets\\split_data\\train\", transform=tr_train)\n",
    "    val_data = ImageFolder(root=r\"datasets\\split_data\\val\", transform=tr_val)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=8, drop_last=True)\n",
    "\n",
    "    max_epoch = 20\n",
    "\n",
    "    # Model selection and freezing logic\n",
    "    if model_name == 'resnet':\n",
    "        model = resnet18(pretrained=pretrained).to(device)\n",
    "        if pretrained:\n",
    "            # Freeze all layers except the final layer\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "            # Replace the fully connected layer\n",
    "            model.fc = nn.Linear(model.fc.in_features, 4)\n",
    "        else:\n",
    "            # Directly modify the FC layer\n",
    "            model.fc = nn.Linear(model.fc.in_features, 4)\n",
    "\n",
    "    elif model_name == 'vgg':\n",
    "        model = vgg16(pretrained=pretrained).to(device)\n",
    "        if pretrained:\n",
    "            # Freeze all layers except the classifier\n",
    "            for param in model.features.parameters():\n",
    "                param.requires_grad = False\n",
    "            # Replace the classifier with a new one\n",
    "            model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, 4)\n",
    "        else:\n",
    "            # Directly modify the classifier\n",
    "            model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, 4)\n",
    "\n",
    "    # Optimizer selection\n",
    "    if optimizer_name == 'sgd':\n",
    "        optimizer = SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, momentum=0.9)\n",
    "    elif optimizer_name == 'adam':\n",
    "        optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "\n",
    "    # Loss function\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Start training\n",
    "    train(model, train_loader, val_loader, optimizer, loss, max_epoch, device, log_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0: 100%|██████████| 350/350 [00:12<00:00, 28.83it/s, loss_st=1.551793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.1809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 36.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6175)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 350/350 [00:11<00:00, 30.81it/s, loss_st=1.259058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 1.0565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 43.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6550)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2: 100%|██████████| 350/350 [00:10<00:00, 31.87it/s, loss_st=0.903561]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 1.0335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 37.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6400)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3: 100%|██████████| 350/350 [00:11<00:00, 31.11it/s, loss_st=1.432855]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 0.9820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 43.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7225)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4: 100%|██████████| 350/350 [00:11<00:00, 31.81it/s, loss_st=0.878720]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 0.9693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 36.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6950)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5: 100%|██████████| 350/350 [00:11<00:00, 31.43it/s, loss_st=0.126218]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 0.9266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 36.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6750)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6: 100%|██████████| 350/350 [00:11<00:00, 30.87it/s, loss_st=1.898372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 0.9437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 44.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7125)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7: 100%|██████████| 350/350 [00:11<00:00, 30.17it/s, loss_st=0.657244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 0.9558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 35.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7100)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8: 100%|██████████| 350/350 [00:11<00:00, 30.78it/s, loss_st=1.364988]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 0.9399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 38.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6900)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9: 100%|██████████| 350/350 [00:11<00:00, 30.59it/s, loss_st=0.467834]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 0.9533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 44.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6950)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 10: 100%|██████████| 350/350 [00:11<00:00, 31.80it/s, loss_st=1.702439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 0.9578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 36.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6925)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 11: 100%|██████████| 350/350 [00:11<00:00, 29.51it/s, loss_st=1.686144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 44.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6975)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 12: 100%|██████████| 350/350 [00:12<00:00, 27.98it/s, loss_st=0.856685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 0.9064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 34.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6775)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 13: 100%|██████████| 350/350 [00:13<00:00, 25.36it/s, loss_st=1.721256]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 0.9361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 36.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6675)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 14: 100%|██████████| 350/350 [00:13<00:00, 25.01it/s, loss_st=0.835460]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 0.9529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 33.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6900)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 15: 100%|██████████| 350/350 [00:11<00:00, 30.01it/s, loss_st=0.731398]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 0.9152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 39.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7075)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 16: 100%|██████████| 350/350 [00:11<00:00, 30.96it/s, loss_st=1.379151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 0.9201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 36.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6775)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 17: 100%|██████████| 350/350 [00:11<00:00, 30.15it/s, loss_st=0.988121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: 0.9095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 42.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6975)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 18: 100%|██████████| 350/350 [00:10<00:00, 31.98it/s, loss_st=1.030281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 0.9338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 35.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6825)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 19: 100%|██████████| 350/350 [00:11<00:00, 31.29it/s, loss_st=0.594720]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 0.9300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 40.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7100)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0: 100%|██████████| 350/350 [00:11<00:00, 29.99it/s, loss_st=1.538528]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.3694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 35.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.4200)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 350/350 [00:11<00:00, 29.19it/s, loss_st=1.251592]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 1.2588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 43.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.5450)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2: 100%|██████████| 350/350 [00:11<00:00, 30.99it/s, loss_st=1.171728]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 1.1927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 35.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.5750)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3: 100%|██████████| 350/350 [00:11<00:00, 29.78it/s, loss_st=1.140490]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 1.1490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 45.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6325)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4: 100%|██████████| 350/350 [00:11<00:00, 30.72it/s, loss_st=0.836557]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 1.1013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 30.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6200)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5: 100%|██████████| 350/350 [00:11<00:00, 30.78it/s, loss_st=1.780923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 1.0806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 38.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6375)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6: 100%|██████████| 350/350 [00:11<00:00, 30.18it/s, loss_st=1.125962]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 1.0645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 36.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6450)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7: 100%|██████████| 350/350 [00:11<00:00, 30.14it/s, loss_st=1.383556]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 1.0424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 36.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6600)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8: 100%|██████████| 350/350 [00:11<00:00, 30.60it/s, loss_st=1.043911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 1.0261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 36.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6625)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9: 100%|██████████| 350/350 [00:11<00:00, 30.24it/s, loss_st=0.927093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 0.9978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 36.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6850)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 10: 100%|██████████| 350/350 [00:11<00:00, 30.28it/s, loss_st=0.932172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 0.9955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 36.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6850)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 11: 100%|██████████| 350/350 [00:11<00:00, 31.28it/s, loss_st=1.069679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 0.9976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 37.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7000)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 12: 100%|██████████| 350/350 [00:11<00:00, 30.55it/s, loss_st=1.319518]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 0.9771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 37.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6725)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 13: 100%|██████████| 350/350 [00:11<00:00, 30.59it/s, loss_st=0.549792]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 0.9760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 36.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7200)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 14: 100%|██████████| 350/350 [00:11<00:00, 30.67it/s, loss_st=0.552794]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 0.9659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 36.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7250)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 15: 100%|██████████| 350/350 [00:11<00:00, 31.09it/s, loss_st=0.806209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 0.9555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 37.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7025)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 16: 100%|██████████| 350/350 [00:11<00:00, 30.53it/s, loss_st=1.042788]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 0.9634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 36.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7175)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 17: 100%|██████████| 350/350 [00:11<00:00, 30.28it/s, loss_st=0.589145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: 0.9508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 35.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7075)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 18: 100%|██████████| 350/350 [00:11<00:00, 30.50it/s, loss_st=0.915405]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 0.9490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 36.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7175)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 19: 100%|██████████| 350/350 [00:11<00:00, 30.83it/s, loss_st=0.891731]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 0.9378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:01<00:00, 37.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7175)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # main(model_name='resnet', optimizer_name='sgd', lr=1e-2, pretrained=False, log_dir='resnet_sgd')\n",
    "    # main(model_name='resnet', optimizer_name='adam', lr=1e-4, pretrained=False, log_dir='resnet_adam')\n",
    "    \n",
    "    main(model_name='resnet', optimizer_name='sgd', lr=1e-3, pretrained=True, log_dir='freeze_resnet_sgd_pretrained')\n",
    "    main(model_name='resnet', optimizer_name='adam', lr=1e-4, pretrained=True, log_dir='freeze_resnet_adam_pretrained')\n",
    "    \n",
    "    # main(model_name='vgg', optimizer_name='sgd', lr=1e-3, pretrained=False, log_dir='vgg_sgd')\n",
    "    # main(model_name='vgg', optimizer_name='adam', lr=1e-4, pretrained=False, log_dir='vgg_adam')\n",
    "    \n",
    "    # main(model_name='vgg', optimizer_name='sgd', lr=1e-3, pretrained=True, log_dir='freeze_vgg_sgd_pretrained')\n",
    "    # main(model_name='vgg', optimizer_name='adam', lr=1e-4, pretrained=True, log_dir='freeze_vgg_adam_pretrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "epoch 0: 100%|██████████| 350/350 [00:22<00:00, 15.31it/s, loss_st=0.739610]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.1455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 23.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6600)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 350/350 [00:22<00:00, 15.37it/s, loss_st=0.786201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 0.9139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 23.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6600)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2: 100%|██████████| 350/350 [00:22<00:00, 15.33it/s, loss_st=0.758595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 0.8178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 23.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6675)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3: 100%|██████████| 350/350 [00:22<00:00, 15.30it/s, loss_st=0.319113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 0.7210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 23.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6775)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4: 100%|██████████| 350/350 [00:24<00:00, 14.09it/s, loss_st=0.201509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 0.6713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 21.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7050)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5: 100%|██████████| 350/350 [00:25<00:00, 13.64it/s, loss_st=1.092625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 0.6243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 20.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7175)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6: 100%|██████████| 350/350 [00:25<00:00, 13.91it/s, loss_st=1.085669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 0.5324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 20.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6700)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7: 100%|██████████| 350/350 [00:25<00:00, 13.86it/s, loss_st=1.293660]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 0.4866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 23.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7100)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8: 100%|██████████| 350/350 [00:24<00:00, 14.34it/s, loss_st=0.743546]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 0.4825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 21.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7075)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9: 100%|██████████| 350/350 [00:25<00:00, 13.98it/s, loss_st=0.587714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 0.4248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 21.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7200)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 10: 100%|██████████| 350/350 [00:24<00:00, 14.02it/s, loss_st=0.045304]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 0.4088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 21.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7225)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 11: 100%|██████████| 350/350 [00:24<00:00, 14.53it/s, loss_st=0.504626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 0.3516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7250)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 12: 100%|██████████| 350/350 [00:22<00:00, 15.37it/s, loss_st=0.031194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 0.3516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 24.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7375)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 13: 100%|██████████| 350/350 [00:23<00:00, 14.86it/s, loss_st=0.069106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 0.2856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 21.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7150)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 14: 100%|██████████| 350/350 [00:24<00:00, 14.17it/s, loss_st=0.059338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 0.3173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 21.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7150)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 15: 100%|██████████| 350/350 [00:23<00:00, 14.86it/s, loss_st=0.315293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 0.2798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 23.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7500)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 16: 100%|██████████| 350/350 [00:23<00:00, 14.59it/s, loss_st=0.039453]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 0.2572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 21.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7375)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 17: 100%|██████████| 350/350 [00:23<00:00, 14.68it/s, loss_st=0.712864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: 0.2450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 23.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7175)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 18: 100%|██████████| 350/350 [00:22<00:00, 15.36it/s, loss_st=0.623820]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 0.2451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 24.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7425)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 19: 100%|██████████| 350/350 [00:22<00:00, 15.37it/s, loss_st=0.197108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 0.2341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 23.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7375)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0: 100%|██████████| 350/350 [00:30<00:00, 11.62it/s, loss_st=0.954704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.2737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 24.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6150)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 350/350 [00:29<00:00, 11.67it/s, loss_st=0.819675]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 1.0335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 23.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6600)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2: 100%|██████████| 350/350 [00:30<00:00, 11.58it/s, loss_st=1.422376]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 0.8862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 23.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.6825)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3: 100%|██████████| 350/350 [00:32<00:00, 10.90it/s, loss_st=1.367169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 0.8220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 21.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7125)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4: 100%|██████████| 350/350 [00:31<00:00, 11.01it/s, loss_st=0.444536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 0.7541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 21.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7325)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5: 100%|██████████| 350/350 [00:31<00:00, 10.96it/s, loss_st=0.895188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 0.6980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7300)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6: 100%|██████████| 350/350 [00:31<00:00, 11.01it/s, loss_st=1.049426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 0.6377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 22.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7325)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7: 100%|██████████| 350/350 [00:31<00:00, 11.07it/s, loss_st=0.056520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 0.5937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 24.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7350)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8: 100%|██████████| 350/350 [00:30<00:00, 11.62it/s, loss_st=0.126969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 0.5491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 24.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7275)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9: 100%|██████████| 350/350 [00:31<00:00, 11.15it/s, loss_st=1.403286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 0.5109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 21.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7275)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 10: 100%|██████████| 350/350 [00:32<00:00, 10.93it/s, loss_st=0.601344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 0.4532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 21.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7375)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 11: 100%|██████████| 350/350 [00:31<00:00, 11.02it/s, loss_st=0.435894]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 0.4163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 21.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7400)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 12: 100%|██████████| 350/350 [00:31<00:00, 11.02it/s, loss_st=0.438934]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 0.3868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 21.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7225)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 13: 100%|██████████| 350/350 [00:31<00:00, 11.07it/s, loss_st=0.143059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 0.3635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 21.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7275)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 14: 100%|██████████| 350/350 [00:30<00:00, 11.40it/s, loss_st=0.112498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 0.3234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 23.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7300)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 15: 100%|██████████| 350/350 [00:30<00:00, 11.47it/s, loss_st=0.117010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 0.3111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 23.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7300)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 16: 100%|██████████| 350/350 [00:30<00:00, 11.53it/s, loss_st=0.547288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 0.2804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 23.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7450)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 17: 100%|██████████| 350/350 [00:30<00:00, 11.53it/s, loss_st=0.482822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: 0.2567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 23.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7525)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 18: 100%|██████████| 350/350 [00:30<00:00, 11.45it/s, loss_st=0.130912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 0.2415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 23.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7575)\n",
      "Saved the model to checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 19: 100%|██████████| 350/350 [00:30<00:00, 11.33it/s, loss_st=0.241274]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 0.2080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 100%|██████████| 50/50 [00:02<00:00, 23.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  tensor(0.7375)\n",
      "Saved the model to checkpoints/\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    main(model_name='vgg', optimizer_name='sgd', lr=1e-3, pretrained=True, log_dir='freeze_vgg_sgd_pretrained')\n",
    "    main(model_name='vgg', optimizer_name='adam', lr=1e-5, pretrained=True, log_dir='freeze_vgg_adam_pretrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_11788\\989400935.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from checkpoints\\vgg_sgd_pretrained.pth\n",
      "Test dataset size: 804 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 101/101 [00:11<00:00,  9.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 Accuracy: 88.06%\n",
      "Class 1 Accuracy: 88.56%\n",
      "Class 2 Accuracy: 79.60%\n",
      "Class 3 Accuracy: 80.60%\n",
      "Classwise Accuracy for vgg (vgg_sgd_pretrained): tensor([88.0597, 88.5572, 79.6020, 80.5970], device='cuda:0')\n",
      "Model loaded successfully from checkpoints\\vgg_adam_pretrained.pth\n",
      "Test dataset size: 804 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 101/101 [00:04<00:00, 21.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 Accuracy: 76.12%\n",
      "Class 1 Accuracy: 90.05%\n",
      "Class 2 Accuracy: 92.04%\n",
      "Class 3 Accuracy: 60.70%\n",
      "Classwise Accuracy for vgg (vgg_adam_pretrained): tensor([76.1194, 90.0498, 92.0398, 60.6965], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as model\n",
    "from torchmetrics import F1Score\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "# Define the VGG16 model class\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.vgg16 = model.vgg16(pretrained=pretrained)\n",
    "        self.vgg16.classifier[-1] = torch.nn.Linear(in_features=4096, out_features=num_classes, bias=True)\n",
    "\n",
    "    def forward(self, image):\n",
    "        out = self.vgg16(image)\n",
    "        return out\n",
    "\n",
    "# Function to evaluate accuracy on the test dataset with classwise accuracy\n",
    "def test(model, test_loader, device, num_classes):\n",
    "    correct_preds = torch.zeros(num_classes).to(device)  # Correct predictions per class\n",
    "    total_preds = torch.zeros(num_classes).to(device)  # Total predictions per class\n",
    "    model.eval()  # Switch model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)  # Get the predicted class\n",
    "\n",
    "            # Update counts for each class\n",
    "            for i in range(num_classes):\n",
    "                correct_preds[i] += ((predicted == i) & (labels == i)).sum().item()  # Correct predictions for class i\n",
    "                total_preds[i] += (labels == i).sum().item()  # Total samples for class i\n",
    "\n",
    "    # Calculate accuracy per class\n",
    "    classwise_accuracy = correct_preds / total_preds * 100\n",
    "\n",
    "    # Print the results\n",
    "    for i in range(num_classes):\n",
    "        print(f\"Class {i} Accuracy: {classwise_accuracy[i]:.2f}%\")\n",
    "\n",
    "    return classwise_accuracy\n",
    "\n",
    "# Function to load model from checkpoint\n",
    "def load_model(checkpoint_path, model, device):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"Model loaded successfully from {checkpoint_path}\")\n",
    "    return model\n",
    "\n",
    "# Function to prepare the test dataset\n",
    "def prepare_test_data(test_data_path, batch_size):\n",
    "    tr_test = transforms.Compose([\n",
    "        transforms.Resize([224, 224]),  # Resize images\n",
    "        transforms.ToTensor(),  # Convert to tensor\n",
    "    ])\n",
    "    \n",
    "    # Load the test dataset\n",
    "    test_data = ImageFolder(root=test_data_path, transform=tr_test)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)  # No need to shuffle for testing\n",
    "    print(f\"Test dataset size: {len(test_data)} samples\")\n",
    "    return test_loader\n",
    "\n",
    "# Main function to train, evaluate, and load models\n",
    "def main(model_name, optimizer_name, lr, pretrained, log_dir, test_data_path):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    torch.cuda.set_per_process_memory_fraction(0.8, device=0)  # Limit GPU memory to 80%\n",
    "\n",
    "    if model_name == 'vgg':\n",
    "        model = VGG16(num_classes=4, pretrained=pretrained).to(device)\n",
    "    elif model_name == 'resnet':\n",
    "        model = ResNet18(num_classes=4, pretrained=pretrained).to(device)\n",
    "\n",
    "    # Load the model\n",
    "    checkpoint_path = os.path.join(\"checkpoints\", log_dir + '.pth')\n",
    "    model = load_model(checkpoint_path, model, device)\n",
    "\n",
    "    # Prepare the test data\n",
    "    test_loader = prepare_test_data(test_data_path, batch_size=8)\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    num_classes = 4  # Set the number of classes in your dataset\n",
    "    classwise_accuracy = test(model, test_loader, device, num_classes)\n",
    "    print(f\"Classwise Accuracy for {model_name} ({log_dir}): {classwise_accuracy}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_data_path = r\"datasets\\split_data\\test\"  # Path to your test dataset\n",
    "\n",
    "    # Example: Test with a pretrained VGG model trained with SGD\n",
    "    main(model_name='vgg', optimizer_name='sgd', lr=1e-3, pretrained=True, log_dir='vgg_sgd_pretrained', test_data_path=test_data_path)\n",
    "    main(model_name='vgg', optimizer_name='sgd', lr=1e-3, pretrained=True, log_dir='vgg_adam_pretrained', test_data_path=test_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as model\n",
    "from torchmetrics import F1Score\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "# Define the VGG16 model class\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.vgg16 = model.vgg16(pretrained=pretrained)\n",
    "        self.vgg16.classifier[-1] = torch.nn.Linear(in_features=4096, out_features=num_classes, bias=True)\n",
    "\n",
    "    def forward(self, image):\n",
    "        out = self.vgg16(image)\n",
    "        return out\n",
    "    # Define the ResNet model class\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.resnet18 = model.resnet18(pretrained=pretrained)\n",
    "        self.resnet18.fc = torch.nn.Linear(in_features=self.resnet18.fc.in_features, out_features=num_classes)\n",
    "\n",
    "    def forward(self, image):\n",
    "        out = self.resnet18(image)\n",
    "        return out\n",
    "    def load_state_dict(self, state_dict, strict=True):\n",
    "        \"\"\"\n",
    "        Custom load_state_dict to handle key mismatches by adding 'resnet18.' prefix.\n",
    "        \"\"\"\n",
    "        # Add 'resnet18.' prefix to each key in the state_dict\n",
    "        state_dict = {f\"resnet18.{key}\": value for key, value in state_dict.items()}\n",
    "        # Now load the modified state_dict into the model\n",
    "        super().load_state_dict(state_dict, strict)\n",
    "\n",
    "\n",
    "# Function to evaluate accuracy on the test dataset with classwise accuracy\n",
    "def test(model, test_loader, device, num_classes):\n",
    "    correct_preds = torch.zeros(num_classes).to(device)  # Correct predictions per class\n",
    "    total_preds = torch.zeros(num_classes).to(device)  # Total predictions per class\n",
    "    model.eval()  # Switch model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)  # Get the predicted class\n",
    "\n",
    "            # Update counts for each class\n",
    "            for i in range(num_classes):\n",
    "                correct_preds[i] += ((predicted == i) & (labels == i)).sum().item()  # Correct predictions for class i\n",
    "                total_preds[i] += (labels == i).sum().item()  # Total samples for class i\n",
    "\n",
    "    # Calculate accuracy per class\n",
    "    classwise_accuracy = correct_preds / total_preds * 100\n",
    "\n",
    "    # Print the results\n",
    "    for i in range(num_classes):\n",
    "        print(f\"Class {i} Accuracy: {classwise_accuracy[i]:.2f}%\")\n",
    "\n",
    "    return classwise_accuracy\n",
    "\n",
    "# Function to load model from checkpoint\n",
    "def load_model(checkpoint_path, model, device):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"Model loaded successfully from {checkpoint_path}\")\n",
    "    return model\n",
    "\n",
    "# Function to prepare the test dataset\n",
    "def prepare_test_data(test_data_path, batch_size):\n",
    "    tr_test = transforms.Compose([\n",
    "        transforms.Resize([224, 224]),  # Resize images\n",
    "        transforms.ToTensor(),  # Convert to tensor\n",
    "    ])\n",
    "    \n",
    "    # Load the test dataset\n",
    "    test_data = ImageFolder(root=test_data_path, transform=tr_test)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)  # No need to shuffle for testing\n",
    "    print(f\"Test dataset size: {len(test_data)} samples\")\n",
    "    return test_loader\n",
    "\n",
    "# Main function to train, evaluate, and load models\n",
    "def main(model_name, optimizer_name, lr, pretrained, log_dir, test_data_path):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    torch.cuda.set_per_process_memory_fraction(0.8, device=0)  # Limit GPU memory to 80%\n",
    "\n",
    "    if model_name == 'vgg':\n",
    "        model = VGG16(num_classes=4, pretrained=pretrained).to(device)\n",
    "    elif model_name == 'resnet':\n",
    "        model = ResNet18(num_classes=4, pretrained=pretrained).to(device)\n",
    "\n",
    "    # Load the model\n",
    "    checkpoint_path = os.path.join(\"checkpoints\", log_dir + '.pth')\n",
    "    model = load_model(checkpoint_path, model, device)\n",
    "\n",
    "    # Prepare the test data\n",
    "    test_loader = prepare_test_data(test_data_path, batch_size=8)\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    num_classes = 4  # Set the number of classes in your dataset\n",
    "    classwise_accuracy = test(model, test_loader, device, num_classes)\n",
    "    print(f\"Classwise Accuracy for {model_name} ({log_dir}): {classwise_accuracy}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14952\\186437167.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from checkpoints\\resnet_sgd.pth\n",
      "Test dataset size: 804 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 101/101 [00:06<00:00, 16.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 Accuracy: 24.88%\n",
      "Class 1 Accuracy: 64.18%\n",
      "Class 2 Accuracy: 74.63%\n",
      "Class 3 Accuracy: 56.22%\n",
      "Classwise Accuracy for resnet (resnet_sgd): tensor([24.8756, 64.1791, 74.6269, 56.2189], device='cuda:0')\n",
      "Model loaded successfully from checkpoints\\resnet_adam.pth\n",
      "Test dataset size: 804 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 101/101 [00:02<00:00, 49.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 Accuracy: 78.11%\n",
      "Class 1 Accuracy: 52.74%\n",
      "Class 2 Accuracy: 68.16%\n",
      "Class 3 Accuracy: 66.67%\n",
      "Classwise Accuracy for resnet (resnet_adam): tensor([78.1095, 52.7363, 68.1592, 66.6667], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_data_path = r\"datasets\\split_data\\test\"  # Path to your test dataset\n",
    "main(model_name='resnet', optimizer_name='sgd', lr=1e-3, pretrained=False, log_dir='resnet_sgd', test_data_path=test_data_path)\n",
    "main(model_name='resnet', optimizer_name='adam', lr=1e-5, pretrained=False, log_dir='resnet_adam', test_data_path=test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14952\\186437167.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from checkpoints\\vgg_sgd.pth\n",
      "Test dataset size: 804 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 101/101 [00:04<00:00, 23.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 Accuracy: 12.44%\n",
      "Class 1 Accuracy: 1.00%\n",
      "Class 2 Accuracy: 6.97%\n",
      "Class 3 Accuracy: 97.01%\n",
      "Classwise Accuracy for vgg (vgg_sgd): tensor([12.4378,  0.9950,  6.9652, 97.0149], device='cuda:0')\n",
      "Model loaded successfully from checkpoints\\vgg_adam.pth\n",
      "Test dataset size: 804 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 101/101 [00:04<00:00, 23.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 Accuracy: 0.00%\n",
      "Class 1 Accuracy: 0.00%\n",
      "Class 2 Accuracy: 0.00%\n",
      "Class 3 Accuracy: 100.00%\n",
      "Classwise Accuracy for vgg (vgg_adam): tensor([  0.,   0.,   0., 100.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_data_path = r\"datasets\\split_data\\test\"  # Path to your test dataset\n",
    "main(model_name='vgg', optimizer_name='sgd', lr=1e-3, pretrained=False, log_dir='vgg_sgd', test_data_path=test_data_path)\n",
    "main(model_name='vgg', optimizer_name='adam', lr=1e-5, pretrained=False, log_dir='vgg_adam', test_data_path=test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14952\\186437167.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from checkpoints\\freeze_resnet_sgd_pretrained.pth\n",
      "Test dataset size: 804 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 101/101 [00:02<00:00, 44.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 Accuracy: 40.80%\n",
      "Class 1 Accuracy: 70.65%\n",
      "Class 2 Accuracy: 75.12%\n",
      "Class 3 Accuracy: 60.70%\n",
      "Classwise Accuracy for resnet (freeze_resnet_sgd_pretrained): tensor([40.7960, 70.6468, 75.1244, 60.6965], device='cuda:0')\n",
      "Model loaded successfully from checkpoints\\freeze_resnet_adam_pretrained.pth\n",
      "Test dataset size: 804 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 101/101 [00:02<00:00, 42.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 Accuracy: 62.69%\n",
      "Class 1 Accuracy: 65.17%\n",
      "Class 2 Accuracy: 65.67%\n",
      "Class 3 Accuracy: 55.22%\n",
      "Classwise Accuracy for resnet (freeze_resnet_adam_pretrained): tensor([62.6866, 65.1741, 65.6716, 55.2239], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_data_path = r\"datasets\\split_data\\test\"  # Path to your test dataset\n",
    "main(model_name='resnet', optimizer_name='sgd', lr=1e-3, pretrained=True, log_dir='freeze_resnet_sgd_pretrained', test_data_path=test_data_path)\n",
    "main(model_name='resnet', optimizer_name='adam', lr=1e-5, pretrained=True, log_dir='freeze_resnet_adam_pretrained', test_data_path=test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, vgg16\n",
    "def main(model_name, optimizer_name, lr, pretrained, log_dir, test_data_path):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    torch.cuda.set_per_process_memory_fraction(0.8, device=0)  # Limit GPU memory to 80%\n",
    "\n",
    "    if model_name == 'resnet':\n",
    "        model = resnet18(pretrained=pretrained).to(device)\n",
    "        if pretrained:\n",
    "            # Freeze all layers except the final layer\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "            # Replace the fully connected layer\n",
    "            model.fc = nn.Linear(model.fc.in_features, 4)\n",
    "        else:\n",
    "            # Directly modify the FC layer\n",
    "            model.fc = nn.Linear(model.fc.in_features, 4)\n",
    "\n",
    "    elif model_name == 'vgg':\n",
    "        model = vgg16(pretrained=pretrained).to(device)\n",
    "        if pretrained:\n",
    "            # Freeze all layers except the classifier\n",
    "            for param in model.features.parameters():\n",
    "                param.requires_grad = False\n",
    "            # Replace the classifier with a new one\n",
    "            model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, 4)\n",
    "        else:\n",
    "            # Directly modify the classifier\n",
    "            model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, 4)\n",
    "\n",
    "    # Load the model\n",
    "    checkpoint_path = os.path.join(\"checkpoints\", log_dir + '.pth')\n",
    "    model = load_model(checkpoint_path, model, device)\n",
    "\n",
    "    # Prepare the test data\n",
    "    test_loader = prepare_test_data(test_data_path, batch_size=8)\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    num_classes = 4  # Set the number of classes in your dataset\n",
    "    classwise_accuracy = test(model, test_loader, device, num_classes)\n",
    "    print(f\"Classwise Accuracy for {model_name} ({log_dir}): {classwise_accuracy}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14952\\186437167.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from checkpoints\\freeze_vgg_sgd_pretrained.pth\n",
      "Test dataset size: 804 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 101/101 [00:04<00:00, 23.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 Accuracy: 73.63%\n",
      "Class 1 Accuracy: 56.72%\n",
      "Class 2 Accuracy: 69.15%\n",
      "Class 3 Accuracy: 79.60%\n",
      "Classwise Accuracy for vgg (freeze_vgg_sgd_pretrained): tensor([73.6318, 56.7164, 69.1542, 79.6020], device='cuda:0')\n",
      "Model loaded successfully from checkpoints\\freeze_vgg_adam_pretrained.pth\n",
      "Test dataset size: 804 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 101/101 [00:04<00:00, 23.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 Accuracy: 76.62%\n",
      "Class 1 Accuracy: 60.70%\n",
      "Class 2 Accuracy: 77.11%\n",
      "Class 3 Accuracy: 75.62%\n",
      "Classwise Accuracy for vgg (freeze_vgg_adam_pretrained): tensor([76.6169, 60.6965, 77.1144, 75.6219], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_data_path = r\"datasets\\split_data\\test\"  # Path to your test dataset\n",
    "main(model_name='vgg', optimizer_name='sgd', lr=1e-3, pretrained=True, log_dir='freeze_vgg_sgd_pretrained', test_data_path=test_data_path)\n",
    "main(model_name='vgg', optimizer_name='adam', lr=1e-5, pretrained=True, log_dir='freeze_vgg_adam_pretrained', test_data_path=test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14952\\1996011608.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from checkpoints\\freeze_vgg_sgd_pretrained.pth\n",
      "Test dataset size: 804 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 101/101 [00:04<00:00, 23.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 69.78%\n",
      "Test Accuracy for vgg (freeze_vgg_sgd_pretrained): 0.6978\n",
      "Model loaded successfully from checkpoints\\freeze_vgg_adam_pretrained.pth\n",
      "Test dataset size: 804 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 101/101 [00:04<00:00, 24.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 72.51%\n",
      "Test Accuracy for vgg (freeze_vgg_adam_pretrained): 0.7251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as model\n",
    "from torchmetrics import F1Score\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "\n",
    "# Function to evaluate accuracy on the test dataset\n",
    "def test(model, test_loader, device):\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    model.eval()  # Switch model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)  # Get the predicted class\n",
    "\n",
    "            # Update counts\n",
    "            correct_preds += (predicted == labels).sum().item()\n",
    "            total_preds += labels.size(0)\n",
    "\n",
    "    accuracy = correct_preds / total_preds\n",
    "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# Function to load model from checkpoint\n",
    "def load_model(checkpoint_path, model, device):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"Model loaded successfully from {checkpoint_path}\")\n",
    "    return model\n",
    "\n",
    "# Function to prepare the test dataset\n",
    "def prepare_test_data(test_data_path, batch_size):\n",
    "    tr_test = transforms.Compose([\n",
    "        transforms.Resize([224, 224]),  # Resize images\n",
    "        transforms.ToTensor(),  # Convert to tensor\n",
    "    ])\n",
    "    \n",
    "    # Load the test dataset\n",
    "    test_data = ImageFolder(root=test_data_path, transform=tr_test)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)  # No need to shuffle for testing\n",
    "    print(f\"Test dataset size: {len(test_data)} samples\")\n",
    "    return test_loader\n",
    "\n",
    "def main(model_name, optimizer_name, lr, pretrained, log_dir, test_data_path):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    torch.cuda.set_per_process_memory_fraction(0.8, device=0)  # Limit GPU memory to 80%\n",
    "\n",
    "    if model_name == 'resnet':\n",
    "        model = resnet18(pretrained=pretrained).to(device)\n",
    "        if pretrained:\n",
    "            # Freeze all layers except the final layer\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "            # Replace the fully connected layer\n",
    "            model.fc = nn.Linear(model.fc.in_features, 4)\n",
    "        else:\n",
    "            # Directly modify the FC layer\n",
    "            model.fc = nn.Linear(model.fc.in_features, 4)\n",
    "\n",
    "    elif model_name == 'vgg':\n",
    "        model = vgg16(pretrained=pretrained).to(device)\n",
    "        if pretrained:\n",
    "            # Freeze all layers except the classifier\n",
    "            for param in model.features.parameters():\n",
    "                param.requires_grad = False\n",
    "            # Replace the classifier with a new one\n",
    "            model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, 4)\n",
    "        else:\n",
    "            # Directly modify the classifier\n",
    "            model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, 4)\n",
    "\n",
    "\n",
    "    # Load the model\n",
    "    checkpoint_path = os.path.join(\"checkpoints\", log_dir + '.pth')\n",
    "    model = load_model(checkpoint_path, model, device)\n",
    "\n",
    "    # Prepare the test data\n",
    "    test_loader = prepare_test_data(test_data_path, batch_size=8)\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    test_accuracy = test(model, test_loader, device)\n",
    "    print(f\"Test Accuracy for {model_name} ({log_dir}): {test_accuracy:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_data_path = r\"datasets\\split_data\\test\"  # Path to your test dataset\n",
    "\n",
    "    # Example: Test with a pretrained VGG model trained with SGD\n",
    "    main(model_name='vgg', optimizer_name='sgd', lr=1e-3, pretrained=True, log_dir='freeze_vgg_sgd_pretrained', test_data_path=test_data_path)\n",
    "    main(model_name='vgg', optimizer_name='adam', lr=1e-5, pretrained=True, log_dir='freeze_vgg_adam_pretrained', test_data_path=test_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14952\\1996011608.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from checkpoints\\freeze_resnet_sgd_pretrained.pth\n",
      "Test dataset size: 804 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 101/101 [00:02<00:00, 37.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 61.82%\n",
      "Test Accuracy for resnet (freeze_resnet_sgd_pretrained): 0.6182\n",
      "Model loaded successfully from checkpoints\\freeze_resnet_adam_pretrained.pth\n",
      "Test dataset size: 804 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 101/101 [00:02<00:00, 39.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 62.19%\n",
      "Test Accuracy for resnet (freeze_resnet_adam_pretrained): 0.6219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_data_path = r\"datasets\\split_data\\test\"  # Path to your test dataset\n",
    "main(model_name='resnet', optimizer_name='sgd', lr=1e-3, pretrained=True, log_dir='freeze_resnet_sgd_pretrained', test_data_path=test_data_path)\n",
    "main(model_name='resnet', optimizer_name='adam', lr=1e-5, pretrained=True, log_dir='freeze_resnet_adam_pretrained', test_data_path=test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
